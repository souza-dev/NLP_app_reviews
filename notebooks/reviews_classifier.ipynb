{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Recuperação dos dados"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Os dados foram obtidos de https://github.com/amitt001/Android-App-Reviews-Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "URL_ROOT = 'https://raw.githubusercontent.com/amitt001/Android-App-Reviews-Dataset/master/'\n",
    "\n",
    "POSITIVE_REVIEWS_DATA_URL = URL_ROOT+'positive10k.txt'\n",
    "NEGATIVE_REVIEWS_DATA_URL = URL_ROOT+'negative10k.txt'\n",
    "\n",
    "DATA_PATH = os.path.join('..', 'data', 'raw')\n",
    "POSITIVE_DATA_FILE = os.path.join(DATA_PATH, 'positive10k.txt')\n",
    "NEGATIVE_DATA_FILE = os.path.join(DATA_PATH, 'negative10k.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "def download_data(data_url, data_path, data_file):\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "    urllib.request.urlretrieve(data_url, data_file)\n",
    "\n",
    "download_data(POSITIVE_REVIEWS_DATA_URL, DATA_PATH, POSITIVE_DATA_FILE)\n",
    "download_data(NEGATIVE_REVIEWS_DATA_URL, DATA_PATH, NEGATIVE_DATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "positive_df = pd.read_csv(POSITIVE_DATA_FILE,  delimiter = \"\\t\", header=None, names=['reviews'])\n",
    "negative_df = pd.read_csv(NEGATIVE_DATA_FILE,  delimiter = \"\\t\", header=None, names=['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adiciona coluna com 0 pra negativo e 1 pra positivo e concatena os dataframes\n",
    "positive_df['label'] = 1\n",
    "negative_df['label'] = 0\n",
    "data = pd.concat([positive_df, negative_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pegando só um amostra pra melhorar o desempenho\n",
    "data = data.sample(frac=0.4, replace=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "source": [
    "# Preparação dos dados"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Download do modelo do spacy e das stopwords do nltk. Descomentar as linhas ao rodas pela primeira vez."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy.cli\n",
    "# spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "source": [
    "## Preparando os dados"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_en = stopwords.words(\"english\")"
   ]
  },
  {
   "source": [
    "Removendo as stopwords que são úteis para a análise do conjunto de stop words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = [ 'not',  \"aren't\", \"couldn't\",]\n",
    "\n",
    "for word in to_remove:\n",
    "    stopwords_en.remove(word)\n"
   ]
  },
  {
   "source": [
    "Função que limpa o texto filtrando somente as letras, retirando as stopword e lematizando. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[\\W\\d_]+\", \" \", text)\n",
    "    text = [word for word in text.split() if word not in stopwords_en]\n",
    "    nlp_text = nlp(\" \".join(text))\n",
    "    tokens = [word.lemma_ if word.lemma_ != \"-PRON-\" else word.lower_ for word in nlp_text]\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviews'] = data['reviews'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "source": [
    "# Testando os modelos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "text = data['reviews']\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True, max_features=5000)\n",
    "X_bow = vectorizer.fit_transform(text)\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf_vect.fit_transform(text)\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_bow, y, test_size=0.3, random_state = 42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_tfidf, y, test_size=0.3, random_state = 42)\n"
   ]
  },
  {
   "source": [
    "## Testando os modelos com o GridSearchCV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifiers():\n",
    "    classifiers = []\n",
    "    classifiers.append(\n",
    "                      ('knn',                              # nome do classificador\n",
    "                        KNeighborsClassifier(),            # instancia do classificador\n",
    "                        {'n_neighbors' : range(1, 33, 2)}  # hiperparametros\n",
    "                      )\n",
    "    )\n",
    "    \n",
    "    classifiers.append(\n",
    "                      ('lr',                               \n",
    "                        LogisticRegression(max_iter=1000), \n",
    "                        {'penalty' : ['l2'], 'C' : [100, 10, 1, 0.1, 0.01]}  \n",
    "                      )\n",
    "    )\n",
    "    \n",
    "    classifiers.append(\n",
    "                      ('dt',\n",
    "                        DecisionTreeClassifier(),\n",
    "                        {'max_depth' : [2, 4, 6, 8, 10, 12]}\n",
    "                      )  \n",
    "    )\n",
    "    \n",
    "    classifiers.append(\n",
    "                      ('rf',\n",
    "                        RandomForestClassifier(),\n",
    "                        {'n_estimators' : [10, 50, 100]}\n",
    "                      ) \n",
    "    )\n",
    "\n",
    "    return classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "classifiers = build_classifiers()\n",
    "\n",
    "for name, model , parameters in classifiers:\n",
    "    print('\\n>> Classifier name: {}'.format(name))\n",
    "    gs = GridSearchCV(estimator=model, param_grid=parameters, refit=True, cv = 5, n_jobs=3)\n",
    "    gs.fit(X1_train, y1_train)\n",
    "    print(\"BOW Best parameters: {}\".format(gs.best_params_))\n",
    "    print(\"BOW Best score: {}\".format(gs.best_score_))\n",
    "    gs.fit(X2_train, y2_train)\n",
    "    print(\"TFIDF Best parameters: {}\".format(gs.best_params_))\n",
    "    print(\"TFIDFBest score: {}\".format(gs.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=1000, C = 1, penalty = 'l2')\n",
    "clf.fit(X2_train, y2_train)\n",
    "y_pred = clf.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_theme()\n",
    "\n",
    "def mostra_metricas(y_true, y_pred):\n",
    "  ''' Função que recebe o y real, o y predito e mostra as\n",
    "  principais metricas.\n",
    "  '''\n",
    "  print(\"Acurácia: \", accuracy_score(y_true, y_pred))\n",
    "  print(\"\\nAUROC:\", roc_auc_score(y_true, y_pred))\n",
    "  print(\"\\nF1-Score:\", f1_score(y_true, y_pred, average='weighted'))\n",
    "  print(\"\\nMatriz de confusão:\")\n",
    "  sns.heatmap(confusion_matrix(y_true, y_pred), annot=True)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostra_metricas(y2_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(text):\n",
    "    text = clean_text(text)\n",
    "    text = tfidf_vect.transform([text])\n",
    "    label = clf.predict(text)[0]\n",
    "    if label == 0:\n",
    "        return \"Negativo\"\n",
    "    elif label == 1:\n",
    "        return \"Positivo\"\n",
    "    else:\n",
    "        return \"Neutro\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = ['Its a good app', \"its a bad app\", \"Better app\", \"Worst app\", \"I like it\", \"I dont like it\"]\n",
    "for review in reviews:\n",
    "    print(f\"Review: {review} --> TAG: {predict_label(review)}\")\n"
   ]
  },
  {
   "source": [
    "# Deploy do modelo\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "DEPLOY_PATH = os.path.join('..', 'model')\n",
    "DEPLOY_FILE = 'finalized.sav'\n",
    "\n",
    "os.makedirs(DEPLOY_PATH, exist_ok=True)\n",
    "\n",
    "deploy_path = os.path.join(DEPLOY_PATH, DEPLOY_FILE)\n",
    "\n",
    "\n",
    "joblib.dump(predict_label, deploy_path)"
   ]
  }
 ]
}